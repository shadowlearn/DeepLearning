{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUORA SPAM FILTER\n",
    "* Filter spam texts in quora by using Text classification with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'D:\\\\Rishabh\\\\Python\\\\DeepLearning\\\\QuoraSpamFilter\\\\train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1306122, 3)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(file_path, sep=',', names=['qid', 'question_text','target'],header=None)[1:]\n",
    "data['target'] = data['target'].astype('int32')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "1  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "2  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "3  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "4  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "5  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "5       0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2,  stratify=data['target'])\n",
    "train_data.shape , test_data.shape\n",
    "\n",
    "x_train = train_data['question_text']\n",
    "y_train  = train_data['target']\n",
    "\n",
    "x_test = test_data['question_text']\n",
    "y_test  = test_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['All', 'is', 'not', 'good', '!', 'rishabh']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('All is not good ! rishabh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len=0\n",
    "for quest in x_train:\n",
    "    txt_len = len(word_tokenize(quest))\n",
    "    if (txt_len > max_len):\n",
    "        max_len = txt_len\n",
    "\n",
    "max_len #412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Quantile value 31.0 and max length is 361\n"
     ]
    }
   ],
   "source": [
    "sent_len=[]\n",
    "sent_len = [len(word_tokenize(quest)) for quest in x_train]\n",
    "print('95% Quantile value {0} and max length is {1}'.format(np.quantile(sent_len, 0.95), np.max(sent_len) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[147, 155, 361, 111, 123, 169, 108, 182, 125, 101]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 35\n",
    "[val for val in sent_len if val>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer(char_level=False, split=' ')\n",
    "tok.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_train = tok.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196106"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len = len(tok.index_word.keys())\n",
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_matrix_train = sequence.pad_sequences(seq_train , maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors\n"
     ]
    }
   ],
   "source": [
    "##Taking all pre trained data in memory\n",
    "glove_file_path = r'D:\\\\Rishabh\\\\Python\\\\Embeddings\\\\GloveData\\\\glove.6B.100d.txt'\n",
    "embed_dict = {}\n",
    "with open(glove_file_path, encoding='utf-8') as text:\n",
    "    for line in text:\n",
    "        #print(line)\n",
    "        word, wts  = line.split(maxsplit=1)\n",
    "        wts        = np.fromstring(wts, 'f',sep=\" \")\n",
    "        embed_dict[word]  = wts\n",
    "\n",
    "print(\"Found %s word vectors\" % len(embed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Found 99207 and not found 96899\n"
     ]
    }
   ],
   "source": [
    "## Preparing Embedding matrix\n",
    "embedding_dim = 100  # As We are using glove data with 100 embeding dimension (100 coefficients of a word) \n",
    "num_tokens    = vocab_len+1\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "words_not_found = []\n",
    "word, i, not_in_glove, word_found = None,0, 0, 0\n",
    "\n",
    "for word , i in tok.word_index.items():\n",
    "    try:\n",
    "        ## Replacing word coefficient fro pre trained model with word in train data at specific index\n",
    "        #embed_vector = embed_dict.get(word) # if using this syntax then need to handle with if embed_vector is None\n",
    "        embed_vector = embed_dict[word]\n",
    "        embedding_matrix[i] = embed_vector\n",
    "        word_found+=1\n",
    "    except:\n",
    "        words_not_found.append(word)\n",
    "        not_in_glove+=1\n",
    "        \n",
    "print(\"Word Found {0} and not found {1}\".format(word_found, not_in_glove) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_LSTM(embedding_matrix, embed_dim, max_len, vocab_size):\n",
    "    inputs = Input(name='inp_layer', shape=[max_len])\n",
    "    \n",
    "    layer  = Embedding(vocab_size+1 , embed_dim, input_length=max_len, mask_zero=True,\n",
    "                      weights=[embedding_matrix],trainable=False)(inputs)\n",
    "    \n",
    "    layer  = LSTM(64)(layer)\n",
    "    layer  = Dense(256, name='FC1', activation='relu')(layer)\n",
    "    layer  = Dropout(0.4)(layer)\n",
    "    layer  = Dense(1, name='output_layer', activation='sigmoid')(layer)\n",
    "    \n",
    "    model  = Model(inputs=inputs, outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN_LSTM(embedding_matrix, embedding_dim, max_len, vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inp_layer (InputLayer)       [(None, 35)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 35, 100)           19610700  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 19,669,837\n",
      "Trainable params: 59,137\n",
      "Non-trainable params: 19,610,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_test = tok.texts_to_sequences(x_test)\n",
    "sequences_matrix_test = sequence.pad_sequences(sequences_test,\n",
    "                                               maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "20898/20898 [==============================] - 436s 20ms/step - loss: 0.1339 - accuracy: 0.9491 - val_loss: 0.1149 - val_accuracy: 0.9546\n",
      "Epoch 2/15\n",
      "20898/20898 [==============================] - 421s 20ms/step - loss: 0.1099 - accuracy: 0.9566 - val_loss: 0.1092 - val_accuracy: 0.9567\n",
      "Epoch 3/15\n",
      "20898/20898 [==============================] - 434s 21ms/step - loss: 0.1037 - accuracy: 0.9589 - val_loss: 0.1075 - val_accuracy: 0.9571\n",
      "Epoch 4/15\n",
      "20898/20898 [==============================] - 506s 24ms/step - loss: 0.1005 - accuracy: 0.9601 - val_loss: 0.1088 - val_accuracy: 0.9574\n",
      "Epoch 5/15\n",
      "20898/20898 [==============================] - 499s 24ms/step - loss: 0.0964 - accuracy: 0.9612 - val_loss: 0.1123 - val_accuracy: 0.9555\n",
      "Epoch 6/15\n",
      "20898/20898 [==============================] - 502s 24ms/step - loss: 0.0945 - accuracy: 0.9617 - val_loss: 0.1096 - val_accuracy: 0.9575\n",
      "Epoch 7/15\n",
      "20898/20898 [==============================] - 557s 27ms/step - loss: 0.0922 - accuracy: 0.9627 - val_loss: 0.1122 - val_accuracy: 0.9569\n",
      "Epoch 8/15\n",
      "20898/20898 [==============================] - 752s 36ms/step - loss: 0.0899 - accuracy: 0.9632 - val_loss: 0.1147 - val_accuracy: 0.9568\n",
      "Epoch 9/15\n",
      "20898/20898 [==============================] - 754s 36ms/step - loss: 0.0878 - accuracy: 0.9640 - val_loss: 0.1145 - val_accuracy: 0.9564\n",
      "Epoch 10/15\n",
      "20898/20898 [==============================] - 758s 36ms/step - loss: 0.0858 - accuracy: 0.9647 - val_loss: 0.1168 - val_accuracy: 0.9565\n",
      "Epoch 11/15\n",
      "20898/20898 [==============================] - 746s 36ms/step - loss: 0.0847 - accuracy: 0.9650 - val_loss: 0.1179 - val_accuracy: 0.9566\n",
      "Epoch 12/15\n",
      "20898/20898 [==============================] - 755s 36ms/step - loss: 0.0827 - accuracy: 0.9658 - val_loss: 0.1235 - val_accuracy: 0.9558\n",
      "Epoch 13/15\n",
      "20898/20898 [==============================] - 756s 36ms/step - loss: 0.0819 - accuracy: 0.9661 - val_loss: 0.1242 - val_accuracy: 0.9561\n",
      "Epoch 14/15\n",
      "20898/20898 [==============================] - 751s 36ms/step - loss: 0.0801 - accuracy: 0.9668 - val_loss: 0.1251 - val_accuracy: 0.9552\n",
      "Epoch 15/15\n",
      "20898/20898 [==============================] - 759s 36ms/step - loss: 0.0789 - accuracy: 0.9671 - val_loss: 0.1243 - val_accuracy: 0.9553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ae7ed9c488>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequence_matrix_train, y_train.values, batch_size=50,\n",
    "         epochs=15, validation_data=(sequences_matrix_test, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9498967786368657"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=model.predict(sequences_matrix_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
